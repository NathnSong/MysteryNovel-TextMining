{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NathnSong/MysteryNovel-TextMining/blob/main/%EB%8C%80%EC%82%AC%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8%EC%B6%94%EC%B6%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aY94kZefb8Q"
      },
      "source": [
        "## 대사스크립트추출\n",
        "### 화자, 청자, 대사 추출\n",
        "- MLP-KTLim/llama-3-Korean-Bllossom-8B\n",
        "- Llma 모델을 한국어로 튜닝한 모델을 사용\n",
        "- 기존 꺽쇠(「, 」) 있는지를 조건으로 확인하여 화자, 청자, 대사를 추출하는 것에 한계가 있음을 확인, LLM을 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxQzZaFLk4oT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33yJ6fXSktzp"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall torch transformers -y\n",
        "# !pip install torch==2.1.2 transformers==4.37.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3ID_KRdk_PE"
      },
      "outputs": [],
      "source": [
        "cd '/content/drive/MyDrive/MysteryNovel-TextMining'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 대사스크립트 추출"
      ],
      "metadata": {
        "id": "mlFFVg92nfF6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpjMPOwIhWBg"
      },
      "outputs": [],
      "source": [
        "# 모델 불러오기\n",
        "import os\n",
        "import torch\n",
        "import re\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLuBJ-CEg08n"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "act_file = \"Act2.txt\"\n",
        "print(f\"\\n******** {act_file} 처리 시작 ********\")\n",
        "# 대사스크립트 번호 적용\n",
        "save_path = f\"대사스크립트_{act_file.replace('.txt', '').replace('Act', '')}.csv\"\n",
        "\n",
        "def sliding_windows(text, window_size=600, stride=300):\n",
        "  return [text[i:i+window_size] for i in range(0, len(text), stride)]\n",
        "\n",
        "# 텍스트 불러오기\n",
        "with open(act_file, encoding=\"utf-8\") as f:\n",
        "    novel_text = f.read()\n",
        "\n",
        "chunks = sliding_windows(novel_text)\n",
        "\n",
        "\n",
        "# 정규표현식으로 꺽쇠로 감싸진 대사 추출\n",
        "def extract_dialogues(text_chunk):\n",
        "  dialogues = re.findall(r'「(.*?)」', text_chunk, re.DOTALL)\n",
        "  return dialogues\n",
        "\n",
        "# 프롬프트\n",
        "def extract_speaker_info_bllossom(text_chunk, dialogue):\n",
        "  PREFIX = \"\"\"\n",
        "  당신은 문학 작품 속 '대사'를 분석하는 AI입니다.\n",
        "\n",
        "  [규칙]\n",
        "  - 아래 문맥에서 꺽쇠(「, 」)로 감싸진 '대사'만 추출하세요.\n",
        "  - '대사' 내용은 절대 바꾸지 마세요.\n",
        "  - 추론이 어려운 경우에는 '불명'으로 답하세요.\n",
        "\n",
        "  - 화자 : 대사 직전/전후에 '는', '말했다', '물었다' 등과 함께 언급되거나, 문맥상 발화자인 인물.\n",
        "  - 청자 : 발화 상대방으로 문맥상 자연스럽게 연결되는 인물.\n",
        "\n",
        "  [출력형식]\n",
        "  {\"화자\": \"화자 이름\", \"청자\": \"청자 이름 또는 불명\", \"내용\": \"대사 내용\"}\n",
        "  \"\"\"\n",
        "\n",
        "  FEWSHOT = \"\"\"\n",
        "  [예시1]\n",
        "  문맥:\n",
        "  \"베라는 말했다. '그걸 믿으라고?' 필립은 웃었다.\"\n",
        "  대사: 「그걸 믿으라고?」\n",
        "  결과: {\"화자\": \"베라\", \"청자\": \"필립\", \"내용\": \"그걸 믿으라고?\"}\n",
        "\n",
        "  [예시2]\n",
        "  문맥:\n",
        "  블로어는 좀 난처한 표정을  지었다. 붉은 벽돌 같은 얼굴빛이 더욱 짙어졌다. 그리고 말하기 거북한 듯 빠른 말투로 지껄였다.\n",
        "  「암스트롱, 당신은 그녀에게 약을 주었겠지요?」\n",
        "  「약을?」암스트롱 의사는 블로어의 얼굴을 쳐다보았다.\n",
        "  「어젯밤에 말이오. 수면제를 주었지요?」\n",
        "  대사 :「주었소. 보통 수면제였소.」\n",
        "  결과 : {\"화자\": \"암스트롱\", \"청자\": \"블로어\", \"내용\": \"주었소. 보통 수면제였소.\"}\n",
        "\n",
        "  [예시3]\n",
        "  문맥:\n",
        "  롬버드는 엷은 미소를 떠올리며 말했다.\n",
        "  「블로어, 당신도 꽤  영리하군. 나는 처음부터 사건이 일어날  것을 예상하고 있었소.」\n",
        "  「어젯밤에는 그런 말을 하지 않았잖소?」\n",
        "  롬버드는 머리를 저었다.\n",
        "  「우리들에게 숨기는 게 있지요?」\n",
        "  「그렇소.」\n",
        "    결과 : {\"화자\": \"블로어\", \"청자\": \"롬버드\", \"내용\": \"우리들에게 숨기는 게 있지요?\"}\n",
        "    결과 : {\"화자\": \"롬버드\", \"청자\": \"블로어\", \"내용\": \"그렇소\"}\n",
        "  \"\"\"\n",
        "\n",
        "  def make_prompt(text_chunk, dialogue):\n",
        "      return f\"{PREFIX}\\n\\n{FEWSHOT}\\n\\n[대상 문맥]\\n{text_chunk}\\n\\n[대사]\\n「{dialogue}」\"\n",
        "\n",
        "  prompt_text = make_prompt(text_chunk, dialogue)\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": prompt_text}\n",
        "  ]\n",
        "\n",
        "  input_ids = tokenizer.apply_chat_template(\n",
        "      messages,\n",
        "      add_generation_prompt=True,\n",
        "      return_tensors=\"pt\"\n",
        "  ).to(model.device)\n",
        "\n",
        "  attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
        "\n",
        "  outputs = model.generate(\n",
        "      input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      max_new_tokens=512,\n",
        "      do_sample=False,\n",
        "      temperature=0.6,\n",
        "      top_p=0.9,\n",
        "      eos_token_id=[tokenizer.eos_token_id]\n",
        "  )\n",
        "\n",
        "  return tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
        "\n",
        "def parse_result(raw_output):\n",
        "  rows = []\n",
        "  rows = []\n",
        "  # 여러 줄로 json 객체가 나올 수 있으니 줄마다 처리\n",
        "  for line in raw_output.strip().splitlines():\n",
        "      line = line.strip()\n",
        "      if not line:\n",
        "          continue\n",
        "      try:\n",
        "          row = json.loads(line)\n",
        "          rows.append({\n",
        "              \"화자\": str(row.get(\"화자\", \"\")).strip(),\n",
        "              \"청자\": str(row.get(\"청자\", \"\")).strip(),\n",
        "              \"내용\": str(row.get(\"내용\", \"\")).strip()\n",
        "          })\n",
        "      except Exception as e:\n",
        "        print(f\" JSON parsing 실패: {line}\\n오류: {e}\")\n",
        "        continue\n",
        "  return rows\n",
        "def clean_content(x):\n",
        "    # dict나 이상한 타입이 있으면 문자열로 바꾸기\n",
        "    if isinstance(x, dict) or isinstance(x, list):\n",
        "        return str(x)\n",
        "    elif pd.isnull(x):\n",
        "        return \"\"\n",
        "    return x\n",
        "\n",
        "chunks = sliding_windows(novel_text)\n",
        "\n",
        "# 이전에 저장된 데이터 불러오기 (있으면 이어서)\n",
        "if os.path.exists(save_path):\n",
        "    existing_df = pd.read_csv(save_path)\n",
        "\n",
        "    # 저장되어 있는 chunk_idx 기준으로\n",
        "    processed_count = existing_df[\"chunk_idx\"].max()+1\n",
        "    all_data = existing_df.to_dict(\"records\")\n",
        "    print(f\" 기존 데이터 {processed_count}개 불러옴, 이어서 처리 시작\")\n",
        "else:\n",
        "    all_data = []\n",
        "    processed_count = 0\n",
        "\n",
        "# 처리 반복\n",
        "for idx, chunk in enumerate(chunks):\n",
        "    if idx < processed_count:\n",
        "        continue  # 이미 처리된 chunk는 스킵\n",
        "\n",
        "    dialogues = extract_dialogues(chunk)\n",
        "\n",
        "    if not dialogues:\n",
        "      print(f\" 대사 없음! 빈 문자열 추가 : {idx+1}\")\n",
        "      # 저장한 데이터 횟수 체크를 위해 idx 같이 저장\n",
        "      all_data.append({\"화자\" : \"\", \"청자\" : \"\", \"내용\": \"\", \"chunk_idx\" : idx})\n",
        "      continue\n",
        "    else:\n",
        "      print(f\"처리 중 ...: {idx+1}/{len(chunks)}\")\n",
        "      chunk_rows = []\n",
        "      for dialogue in dialogues:\n",
        "        raw = extract_speaker_info_bllossom(chunk, dialogue)\n",
        "        print(\"모델 응답:\\n\", raw[:300].strip())\n",
        "        rows = parse_result(raw)\n",
        "\n",
        "        # 내용이 비어있으면 직접 dialogue 채워넣기\n",
        "        for row in rows:\n",
        "          if not row.get(\"내용\"):\n",
        "            row[\"내용\"] = dialogue\n",
        "          row[\"chunk_idx\"] = idx\n",
        "        chunk_rows.extend(rows)\n",
        "\n",
        "      # 여기서 chunk 데이터 추가\n",
        "      all_data.extend(chunk_rows)\n",
        "\n",
        "    # chunk 자동 저장\n",
        "    if (idx+1) % 5 == 0:\n",
        "      temp_df = pd.DataFrame(all_data)\n",
        "      temp_df[\"내용\"] = temp_df[\"내용\"].apply(clean_content)\n",
        "      temp_df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
        "      print(f\"임시 저장 완료: {idx+1}개 완료\")\n",
        "\n",
        "# 최종 저장\n",
        "\n",
        "print(type(all_data))\n",
        "print(type(all_data[0]))\n",
        "print(all_data[0])\n",
        "final_df = pd.DataFrame(all_data)\n",
        "\n",
        "# value 값 안에 dict 가 들어가는 문제 해결\n",
        "final_df[\"화자\"] = final_df[\"화자\"].apply(clean_content)\n",
        "final_df[\"청자\"] = final_df[\"청자\"].apply(clean_content)\n",
        "final_df[\"내용\"] = final_df[\"내용\"].apply(clean_content)\n",
        "\n",
        "final_df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
        "print(\"대사 추출 최종 완료:\", save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U23sP7CydN99"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "act_file = \"Act4.txt\"\n",
        "print(f\"\\n******** {act_file} 처리 시작 ********\")\n",
        "# 대사스크립트 번호 적용\n",
        "save_path = f\"대사스크립트_{act_file.replace('.txt', '').replace('Act', '')}.csv\"\n",
        "\n",
        "def sliding_windows(text, window_size=600, stride=300):\n",
        "  return [text[i:i+window_size] for i in range(0, len(text), stride)]\n",
        "\n",
        "# 텍스트 불러오기\n",
        "with open(act_file, encoding=\"utf-8\") as f:\n",
        "    novel_text = f.read()\n",
        "\n",
        "chunks = sliding_windows(novel_text)\n",
        "\n",
        "\n",
        "# 정규표현식으로 꺽쇠로 감싸진 대사 추출\n",
        "def extract_dialogues(text_chunk):\n",
        "  dialogues = re.findall(r'「(.*?)」', text_chunk, re.DOTALL)\n",
        "  return dialogues\n",
        "\n",
        "# 프롬프트\n",
        "def extract_speaker_info_bllossom(text_chunk, dialogue):\n",
        "  PREFIX = \"\"\"\n",
        "  당신은 문학 작품 속 '대사'를 분석하는 AI입니다.\n",
        "\n",
        "  [규칙]\n",
        "  - 아래 문맥에서 꺽쇠(「, 」)로 감싸진 '대사'만 추출하세요.\n",
        "  - '대사' 내용은 절대 바꾸지 마세요.\n",
        "  - 추론이 어려운 경우에는 '불명'으로 답하세요.\n",
        "\n",
        "  - 화자 : 대사 직전/전후에 '는', '말했다', '물었다' 등과 함께 언급되거나, 문맥상 발화자인 인물.\n",
        "  - 청자 : 발화 상대방으로 문맥상 자연스럽게 연결되는 인물.\n",
        "\n",
        "  [출력형식]\n",
        "  {\"화자\": \"화자 이름\", \"청자\": \"청자 이름 또는 불명\", \"내용\": \"대사 내용\"}\n",
        "  \"\"\"\n",
        "\n",
        "  FEWSHOT = \"\"\"\n",
        "  [예시1]\n",
        "  문맥:\n",
        "  \"베라는 말했다. '그걸 믿으라고?' 필립은 웃었다.\"\n",
        "  대사: 「그걸 믿으라고?」\n",
        "  결과: {\"화자\": \"베라\", \"청자\": \"필립\", \"내용\": \"그걸 믿으라고?\"}\n",
        "\n",
        "  [예시2]\n",
        "  문맥:\n",
        "  블로어는 좀 난처한 표정을  지었다. 붉은 벽돌 같은 얼굴빛이 더욱 짙어졌다. 그리고 말하기 거북한 듯 빠른 말투로 지껄였다.\n",
        "  「암스트롱, 당신은 그녀에게 약을 주었겠지요?」\n",
        "  「약을?」암스트롱 의사는 블로어의 얼굴을 쳐다보았다.\n",
        "  「어젯밤에 말이오. 수면제를 주었지요?」\n",
        "  대사 :「주었소. 보통 수면제였소.」\n",
        "  결과 : {\"화자\": \"암스트롱\", \"청자\": \"블로어\", \"내용\": \"주었소. 보통 수면제였소.\"}\n",
        "\n",
        "  [예시3]\n",
        "  문맥:\n",
        "  롬버드는 엷은 미소를 떠올리며 말했다.\n",
        "  「블로어, 당신도 꽤  영리하군. 나는 처음부터 사건이 일어날  것을 예상하고 있었소.」\n",
        "  「어젯밤에는 그런 말을 하지 않았잖소?」\n",
        "  롬버드는 머리를 저었다.\n",
        "  「우리들에게 숨기는 게 있지요?」\n",
        "  「그렇소.」\n",
        "    결과 : {\"화자\": \"블로어\", \"청자\": \"롬버드\", \"내용\": \"우리들에게 숨기는 게 있지요?\"}\n",
        "    결과 : {\"화자\": \"롬버드\", \"청자\": \"블로어\", \"내용\": \"그렇소\"}\n",
        "  \"\"\"\n",
        "\n",
        "  def make_prompt(text_chunk, dialogue):\n",
        "      return f\"{PREFIX}\\n\\n{FEWSHOT}\\n\\n[대상 문맥]\\n{text_chunk}\\n\\n[대사]\\n「{dialogue}」\"\n",
        "\n",
        "  prompt_text = make_prompt(text_chunk, dialogue)\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": prompt_text}\n",
        "  ]\n",
        "\n",
        "  input_ids = tokenizer.apply_chat_template(\n",
        "      messages,\n",
        "      add_generation_prompt=True,\n",
        "      return_tensors=\"pt\"\n",
        "  ).to(model.device)\n",
        "\n",
        "  attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
        "\n",
        "  outputs = model.generate(\n",
        "      input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      max_new_tokens=512,\n",
        "      do_sample=False,\n",
        "      temperature=0.6,\n",
        "      top_p=0.9,\n",
        "      eos_token_id=[tokenizer.eos_token_id]\n",
        "  )\n",
        "\n",
        "  return tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
        "\n",
        "def parse_result(raw_output):\n",
        "  rows = []\n",
        "  rows = []\n",
        "  # 여러 줄로 json 객체가 나올 수 있으니 줄마다 처리\n",
        "  for line in raw_output.strip().splitlines():\n",
        "      line = line.strip()\n",
        "      if not line:\n",
        "          continue\n",
        "      try:\n",
        "          row = json.loads(line)\n",
        "          rows.append({\n",
        "              \"화자\": str(row.get(\"화자\", \"\")).strip(),\n",
        "              \"청자\": str(row.get(\"청자\", \"\")).strip(),\n",
        "              \"내용\": str(row.get(\"내용\", \"\")).strip()\n",
        "          })\n",
        "      except Exception as e:\n",
        "        print(f\" JSON parsing 실패: {line}\\n오류: {e}\")\n",
        "        continue\n",
        "  return rows\n",
        "def clean_content(x):\n",
        "    # dict나 이상한 타입이 있으면 문자열로 바꾸기\n",
        "    if isinstance(x, dict) or isinstance(x, list):\n",
        "        return str(x)\n",
        "    elif pd.isnull(x):\n",
        "        return \"\"\n",
        "    return x\n",
        "\n",
        "chunks = sliding_windows(novel_text)\n",
        "\n",
        "# 이전에 저장된 데이터 불러오기 (있으면 이어서)\n",
        "if os.path.exists(save_path):\n",
        "    existing_df = pd.read_csv(save_path)\n",
        "\n",
        "    # 저장되어 있는 chunk_idx 기준으로\n",
        "    processed_count = existing_df[\"chunk_idx\"].max()+1\n",
        "    all_data = existing_df.to_dict(\"records\")\n",
        "    print(f\" 기존 데이터 {processed_count}개 불러옴, 이어서 처리 시작\")\n",
        "else:\n",
        "    all_data = []\n",
        "    processed_count = 0\n",
        "\n",
        "# 처리 반복\n",
        "for idx, chunk in enumerate(chunks):\n",
        "    if idx < processed_count:\n",
        "        continue  # 이미 처리된 chunk는 스킵\n",
        "\n",
        "    dialogues = extract_dialogues(chunk)\n",
        "\n",
        "    if not dialogues:\n",
        "      print(f\" 대사 없음! 빈 문자열 추가 : {idx+1}\")\n",
        "      # 저장한 데이터 횟수 체크를 위해 idx 같이 저장\n",
        "      all_data.append({\"화자\" : \"\", \"청자\" : \"\", \"내용\": \"\", \"chunk_idx\" : idx})\n",
        "      continue\n",
        "    else:\n",
        "      print(f\"처리 중 ...: {idx+1}/{len(chunks)}\")\n",
        "      chunk_rows = []\n",
        "      for dialogue in dialogues:\n",
        "        raw = extract_speaker_info_bllossom(chunk, dialogue)\n",
        "        print(\"모델 응답:\\n\", raw[:300].strip())\n",
        "        rows = parse_result(raw)\n",
        "\n",
        "        # 내용이 비어있으면 직접 dialogue 채워넣기\n",
        "        for row in rows:\n",
        "          if not row.get(\"내용\"):\n",
        "            row[\"내용\"] = dialogue\n",
        "          row[\"chunk_idx\"] = idx\n",
        "        chunk_rows.extend(rows)\n",
        "\n",
        "      # 여기서 chunk 데이터 추가\n",
        "      all_data.extend(chunk_rows)\n",
        "\n",
        "    # chunk 자동 저장\n",
        "    if (idx+1) % 5 == 0:\n",
        "      temp_df = pd.DataFrame(all_data)\n",
        "      temp_df[\"내용\"] = temp_df[\"내용\"].apply(clean_content)\n",
        "      temp_df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
        "      print(f\"임시 저장 완료: {idx+1}개 완료\")\n",
        "\n",
        "# 최종 저장\n",
        "\n",
        "print(type(all_data))\n",
        "print(type(all_data[0]))\n",
        "print(all_data[0])\n",
        "final_df = pd.DataFrame(all_data)\n",
        "\n",
        "# value 값 안에 dict 가 들어가는 문제 해결\n",
        "final_df[\"화자\"] = final_df[\"화자\"].apply(clean_content)\n",
        "final_df[\"청자\"] = final_df[\"청자\"].apply(clean_content)\n",
        "final_df[\"내용\"] = final_df[\"내용\"].apply(clean_content)\n",
        "\n",
        "final_df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
        "print(\"대사 추출 최종 완료:\", save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTsRyAqRolvJ"
      },
      "source": [
        "## Act1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일 로드\n",
        "df = pd.read_csv(\"대사스크립트_1.csv\")\n",
        "df = df.fillna(\"불명\")\n",
        "\n",
        "# 1단계 : 내용이 같고, 하나는 화자 or 청자가 불명이고, 하나는 명확할 때 -> 불명 쪽 삭제\n",
        "mask_same_content = df.duplicated(subset = ['내용'], keep=False)\n",
        "sub_df = df[mask_same_content].copy()\n",
        "\n",
        "to_remove = []\n",
        "for content, group in sub_df.groupby(\"내용\"):\n",
        "  if len(group) <= 1:\n",
        "    continue\n",
        "\n",
        "  # 명확한 화자 or 청자 존재\n",
        "  has_identified = group[(group['화자'] != '불명') & (group['청자'] != '불명')]\n",
        "\n",
        "  # 불명인 쪽만 골라낸다\n",
        "  has_fully_unknown = group[(group['화자'] == '불명') | (group['청자'] == '불명')]\n",
        "\n",
        "  # 명확한 사람도 있고, 완전 불명도 있으면 -> 불명 제거\n",
        "  if not has_identified.empty and not has_fully_unknown.empty:\n",
        "    to_remove.extend(has_fully_unknown.index.tolist())\n",
        "\n",
        "df = df.drop(index = to_remove)\n",
        "\n",
        "df = df.drop_duplicates(subset=['화자', '청자', '내용'], keep = 'first')\n",
        "\n",
        "#저장\n",
        "df.to_csv(\"대사_중복제거1.csv\", index=False)\n",
        "print(\"중복 제거 완료!\")"
      ],
      "metadata": {
        "id": "FewANAO4bnD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. 불러오기 및 chunk_index 제거\n",
        "df = pd.read_csv(\"대사_중복제거1.csv\")\n",
        "df = df.fillna(\"불명\")\n",
        "\n",
        "# 2. 중복 내용 그룹 필터링\n",
        "duplicates = df[df.duplicated(subset=['내용'], keep=False)]\n",
        "\n",
        "# 3. 수동 선택 저장용 리스트\n",
        "rows_to_keep = []\n",
        "\n",
        "# 4. 그룹별 수동 선택\n",
        "for content, group in duplicates.groupby('내용'):\n",
        "    print(f\"\\n내용: {content}\\n\")\n",
        "    group = group.reset_index()  # 원래 인덱스를 새로운 컬럼으로 유지\n",
        "    for i, row in group.iterrows():\n",
        "        print(f\"{i + 1}. 화자: {row['화자']}, 청자: {row['청자']}\")\n",
        "    print(\"0. 삭제\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            choice = int(input(\"몇 번을 남기시겠어요? (0 = 전체 삭제): \"))\n",
        "            if choice == 0:\n",
        "                break\n",
        "            elif 1 <= choice <= len(group):\n",
        "                selected_index = group.loc[choice - 1, 'index']\n",
        "                rows_to_keep.append(selected_index)\n",
        "                break\n",
        "            else:\n",
        "                print(\"잘못된 번호입니다.\")\n",
        "        except ValueError:\n",
        "            print(\"숫자로 입력해주세요.\")\n",
        "\n",
        "# 5. 선택한 행 + 중복 아니었던 행\n",
        "df_keep = df.loc[rows_to_keep]\n",
        "df_non_dup = df.drop(index=duplicates.index)\n",
        "final_df = pd.concat([df_keep, df_non_dup])\n",
        "\n",
        "# chunk_idx 기준 정렬\n",
        "if 'chunk_idx' in final_df.columns:\n",
        "    final_df = final_df.sort_values(by='chunk_idx').reset_index(drop=True)\n",
        "    final_df = final_df.drop(columns=['chunk_idx'])\n",
        "\n",
        "# 7. 저장\n",
        "final_df.to_csv(\"대사_중복제거1.csv\", index=False)\n",
        "print(\"\\n수동 중복 제거 완료 + 순서 정렬 + chunk_index 완전 제거!\")\n"
      ],
      "metadata": {
        "id": "eFRJv_twjs2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Act3"
      ],
      "metadata": {
        "id": "oshitsjRNJtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일 로드\n",
        "df = pd.read_csv(\"대사스크립트_3.csv\")\n",
        "df = df.fillna(\"불명\")\n",
        "\n",
        "# 1단계 : 내용이 같고, 하나는 화자 or 청자가 불명이고, 하나는 명확할 때 -> 불명 쪽 삭제\n",
        "mask_same_content = df.duplicated(subset = ['내용'], keep=False)\n",
        "sub_df = df[mask_same_content].copy()\n",
        "\n",
        "to_remove = []\n",
        "for content, group in sub_df.groupby(\"내용\"):\n",
        "  if len(group) <= 1:\n",
        "    continue\n",
        "\n",
        "  # 명확한 화자 or 청자 존재\n",
        "  has_identified = group[(group['화자'] != '불명') & (group['청자'] != '불명')]\n",
        "\n",
        "  # 불명인 쪽만 골라낸다\n",
        "  has_fully_unknown = group[(group['화자'] == '불명') | (group['청자'] == '불명')]\n",
        "\n",
        "  # 명확한 사람도 있고, 완전 불명도 있으면 -> 불명 제거\n",
        "  if not has_identified.empty and not has_fully_unknown.empty:\n",
        "    to_remove.extend(has_fully_unknown.index.tolist())\n",
        "\n",
        "df = df.drop(index = to_remove)\n",
        "\n",
        "df = df.drop_duplicates(subset=['화자', '청자', '내용'], keep = 'first')\n",
        "\n",
        "#저장\n",
        "df.to_csv(\"대사_중복제거3.csv\", index=False)\n",
        "print(\"중복 제거 완료!\")"
      ],
      "metadata": {
        "id": "NhGBEmCkNKYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. 불러오기 및 chunk_index 제거\n",
        "df = pd.read_csv(\"대사_중복제거3.csv\")\n",
        "df = df.fillna(\"불명\")\n",
        "\n",
        "# 2. 중복 내용 그룹 필터링\n",
        "duplicates = df[df.duplicated(subset=['내용'], keep=False)]\n",
        "\n",
        "# 3. 수동 선택 저장용 리스트\n",
        "rows_to_keep = []\n",
        "\n",
        "# 4. 그룹별 수동 선택\n",
        "for content, group in duplicates.groupby('내용'):\n",
        "    print(f\"\\n내용: {content}\\n\")\n",
        "    group = group.reset_index()  # 원래 인덱스를 새로운 컬럼으로 유지\n",
        "    for i, row in group.iterrows():\n",
        "        print(f\"{i + 1}. 화자: {row['화자']}, 청자: {row['청자']}\")\n",
        "    print(\"0. 삭제\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            choice = int(input(\"몇 번을 남기시겠어요? (0 = 전체 삭제): \"))\n",
        "            if choice == 0:\n",
        "                break\n",
        "            elif 1 <= choice <= len(group):\n",
        "                selected_index = group.loc[choice - 1, 'index']\n",
        "                rows_to_keep.append(selected_index)\n",
        "                break\n",
        "            else:\n",
        "                print(\"잘못된 번호입니다.\")\n",
        "        except ValueError:\n",
        "            print(\"숫자로 입력해주세요.\")\n",
        "\n",
        "# 5. 선택한 행 + 중복 아니었던 행\n",
        "df_keep = df.loc[rows_to_keep]\n",
        "df_non_dup = df.drop(index=duplicates.index)\n",
        "final_df = pd.concat([df_keep, df_non_dup])\n",
        "\n",
        "# chunk_idx 기준 정렬\n",
        "if 'chunk_idx' in final_df.columns:\n",
        "    final_df = final_df.sort_values(by='chunk_idx').reset_index(drop=True)\n",
        "    final_df = final_df.drop(columns=['chunk_idx'])\n",
        "\n",
        "# 7. 저장\n",
        "final_df.to_csv(\"대사_중복제거3.csv\", index=False)\n",
        "print(\"\\n수동 중복 제거 완료 + 순서 정렬 + chunk_index 완전 제거!\")"
      ],
      "metadata": {
        "id": "XzHn3zcNNKmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htyZg661lU3h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Act2"
      ],
      "metadata": {
        "id": "ku8MfJzJkFsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일 로드\n",
        "df = pd.read_csv(\"대사스크립트_2.csv\")\n",
        "df = df.fillna(\"불명\")\n",
        "\n",
        "# 1단계 : 내용이 같고, 하나는 화자 or 청자가 불명이고, 하나는 명확할 때 -> 불명 쪽 삭제\n",
        "mask_same_content = df.duplicated(subset = ['내용'], keep=False)\n",
        "sub_df = df[mask_same_content].copy()\n",
        "\n",
        "to_remove = []\n",
        "for content, group in sub_df.groupby(\"내용\"):\n",
        "  if len(group) <= 1:\n",
        "    continue\n",
        "\n",
        "  # 명확한 화자 or 청자 존재\n",
        "  has_identified = group[(group['화자'] != '불명') & (group['청자'] != '불명')]\n",
        "\n",
        "  # 불명인 쪽만 골라낸다\n",
        "  has_fully_unknown = group[(group['화자'] == '불명') | (group['청자'] == '불명')]\n",
        "\n",
        "  # 명확한 사람도 있고, 완전 불명도 있으면 -> 불명 제거\n",
        "  if not has_identified.empty and not has_fully_unknown.empty:\n",
        "    to_remove.extend(has_fully_unknown.index.tolist())\n",
        "\n",
        "df = df.drop(index = to_remove)\n",
        "\n",
        "df = df.drop_duplicates(subset=['화자', '청자', '내용'], keep = 'first')\n",
        "\n",
        "#저장\n",
        "df.to_csv(\"대사_중복제거2.csv\", index=False)\n",
        "print(\"중복 제거 완료!\")"
      ],
      "metadata": {
        "id": "oDqElzssovwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq5cbazfkJWb"
      },
      "outputs": [],
      "source": [
        "1import pandas as pd\n",
        "\n",
        "# 1. 불러오기 및 chunk_index 제거\n",
        "df = pd.read_csv(\"대사_중복제거2.csv\")\n",
        "df = df.fillna(\"불명\")\n",
        "\n",
        "# 2. 중복 내용 그룹 필터링\n",
        "duplicates = df[df.duplicated(subset=['내용'], keep=False)]\n",
        "\n",
        "# 3. 수동 선택 저장용 리스트\n",
        "rows_to_keep = []\n",
        "\n",
        "# 4. 그룹별 수동 선택\n",
        "for content, group in duplicates.groupby('내용'):\n",
        "    print(f\"\\n내용: {content}\\n\")\n",
        "    group = group.reset_index()  # 원래 인덱스를 새로운 컬럼으로 유지\n",
        "    for i, row in group.iterrows():\n",
        "        print(f\"{i + 1}. 화자: {row['화자']}, 청자: {row['청자']}\")\n",
        "    print(\"0. 삭제\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            choice = int(input(\"몇 번을 남기시겠어요? (0 = 전체 삭제): \"))\n",
        "            if choice == 0:\n",
        "                break\n",
        "            elif 1 <= choice <= len(group):\n",
        "                selected_index = group.loc[choice - 1, 'index']\n",
        "                rows_to_keep.append(selected_index)\n",
        "                break\n",
        "            else:\n",
        "                print(\"잘못된 번호입니다.\")\n",
        "        except ValueError:\n",
        "            print(\"숫자로 입력해주세요.\")\n",
        "\n",
        "# 5. 선택한 행 + 중복 아니었던 행\n",
        "df_keep = df.loc[rows_to_keep]\n",
        "df_non_dup = df.drop(index=duplicates.index)\n",
        "final_df = pd.concat([df_keep, df_non_dup])\n",
        "\n",
        "# chunk_idx 기준 정렬\n",
        "if 'chunk_idx' in final_df.columns:\n",
        "    final_df = final_df.sort_values(by='chunk_idx').reset_index(drop=True)\n",
        "    final_df = final_df.drop(columns=['chunk_idx'])\n",
        "\n",
        "# 7. 저장\n",
        "final_df.to_csv(\"대사_중복제거2.csv\", index=False)\n",
        "print(\"\\n수동 중복 제거 완료 + 순서 정렬 + chunk_index 완전 제거!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Act4"
      ],
      "metadata": {
        "id": "D1Fwk9w1ojmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일 로드\n",
        "df = pd.read_csv(\"대사스크립트_4.csv\")\n",
        "df = df.fillna(\"불명\")\n",
        "\n",
        "# 1단계 : 내용이 같고, 하나는 화자 or 청자가 불명이고, 하나는 명확할 때 -> 불명 쪽 삭제\n",
        "mask_same_content = df.duplicated(subset = ['내용'], keep=False)\n",
        "sub_df = df[mask_same_content].copy()\n",
        "\n",
        "to_remove = []\n",
        "for content, group in sub_df.groupby(\"내용\"):\n",
        "  if len(group) <= 1:\n",
        "    continue\n",
        "\n",
        "  # 명확한 화자 or 청자 존재\n",
        "  has_identified = group[(group['화자'] != '불명') & (group['청자'] != '불명')]\n",
        "\n",
        "  # 불명인 쪽만 골라낸다\n",
        "  has_fully_unknown = group[(group['화자'] == '불명') | (group['청자'] == '불명')]\n",
        "\n",
        "  # 명확한 사람도 있고, 완전 불명도 있으면 -> 불명 제거\n",
        "  if not has_identified.empty and not has_fully_unknown.empty:\n",
        "    to_remove.extend(has_fully_unknown.index.tolist())\n",
        "\n",
        "df = df.drop(index = to_remove)\n",
        "\n",
        "df = df.drop_duplicates(subset=['화자', '청자', '내용'], keep = 'first')\n",
        "\n",
        "#저장\n",
        "df.to_csv(\"대사_중복제거4.csv\", index=False)\n",
        "print(\"중복 제거 완료!\")"
      ],
      "metadata": {
        "id": "Ws078BPDrGZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1import pandas as pd\n",
        "\n",
        "# 1. 불러오기 및 chunk_index 제거\n",
        "df = pd.read_csv(\"대사_중복제거4.csv\")\n",
        "df = df.fillna(\"불명\")\n",
        "\n",
        "# 2. 중복 내용 그룹 필터링\n",
        "duplicates = df[df.duplicated(subset=['내용'], keep=False)]\n",
        "\n",
        "# 3. 수동 선택 저장용 리스트\n",
        "rows_to_keep = []\n",
        "\n",
        "# 4. 그룹별 수동 선택\n",
        "for content, group in duplicates.groupby('내용'):\n",
        "    print(f\"\\n내용: {content}\\n\")\n",
        "    group = group.reset_index()  # 원래 인덱스를 새로운 컬럼으로 유지\n",
        "    for i, row in group.iterrows():\n",
        "        print(f\"{i + 1}. 화자: {row['화자']}, 청자: {row['청자']}\")\n",
        "    print(\"0. 삭제\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            choice = int(input(\"몇 번을 남기시겠어요? (0 = 전체 삭제): \"))\n",
        "            if choice == 0:\n",
        "                break\n",
        "            elif 1 <= choice <= len(group):\n",
        "                selected_index = group.loc[choice - 1, 'index']\n",
        "                rows_to_keep.append(selected_index)\n",
        "                break\n",
        "            else:\n",
        "                print(\"잘못된 번호입니다.\")\n",
        "        except ValueError:\n",
        "            print(\"숫자로 입력해주세요.\")\n",
        "\n",
        "# 5. 선택한 행 + 중복 아니었던 행\n",
        "df_keep = df.loc[rows_to_keep]\n",
        "df_non_dup = df.drop(index=duplicates.index)\n",
        "final_df = pd.concat([df_keep, df_non_dup])\n",
        "\n",
        "# chunk_idx 기준 정렬\n",
        "if 'chunk_idx' in final_df.columns:\n",
        "    final_df = final_df.sort_values(by='chunk_idx').reset_index(drop=True)\n",
        "    final_df = final_df.drop(columns=['chunk_idx'])\n",
        "\n",
        "# 7. 저장\n",
        "final_df.to_csv(\"대사_중복제거4.csv\", index=False)\n",
        "print(\"\\n수동 중복 제거 완료 + 순서 정렬 + chunk_index 완전 제거!\")"
      ],
      "metadata": {
        "id": "TsbC9rfxrI0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인물 빈도수 추출"
      ],
      "metadata": {
        "id": "U61C5RvarSP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "file_list = [\n",
        "    \"대사_중복제거1.csv\",\n",
        "    \"대사_중복제거2.csv\",\n",
        "    \"대사_중복제거3.csv\",\n",
        "    \"대사_중복제거4.csv\"\n",
        "]\n",
        "\n",
        "# 2. CSV 합치기\n",
        "dfs = [pd.read_csv(file).fillna(\"불명\") for file in file_list]\n",
        "merged_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# 3. 화자 + 청자 합쳐서 빈도 계산\n",
        "characters = merged_df['화자'].tolist() + merged_df['청자'].tolist()\n",
        "character_counts = Counter([c for c in characters if c != \"불명\"])\n",
        "\n",
        "\n",
        "# 정렬된 결과를 DataFrame으로 보기 좋게 정리\n",
        "freq_df = pd.DataFrame(character_counts.items(), columns=[\"등장인물\", \"등장횟수\"])\n",
        "freq_df = freq_df.sort_values(by=\"등장횟수\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# # 저장 (선택 사항)\n",
        "# freq_df.to_csv(\"등장인물_빈도수.csv\", index=False)\n",
        "\n",
        "# 출력\n",
        "freq_df"
      ],
      "metadata": {
        "id": "wu8dA-WXu5Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이름 정규화\n",
        "alias_dict = {\n",
        "    # 주요인물 10인\n",
        "    \"베러\": \"베러 크레이슨\",\n",
        "    \"크레이슨\": \"베러 크레이슨\",\n",
        "    \"크레이슨 선생님\": \"베러 크레이슨\",\n",
        "    \"배러\": \"베러 크레이슨\",\n",
        "    \"베라\": \"베러 크레이슨\",\n",
        "\n",
        "    \"워그레이브\": \"로렌스 워그레이브\",\n",
        "    \"워그레이브 판사\": \"로렌스 워그레이브\",\n",
        "    \"판사\": \"로렌스 워그레이브\",\n",
        "\n",
        "    \"브랜트\": \"에밀리 브랜트\",\n",
        "    \"에밀리\": \"에밀리 브랜트\",\n",
        "    \"에밀리 브랜트\": \"에밀리 브랜트\",\n",
        "    \"미스 브랜트\": \"에밀리 브랜트\",\n",
        "    \"미스 브란트\": \"에밀리 브랜트\",\n",
        "    \"밀리 브랜트\": \"에밀리 브랜트\",\n",
        "\n",
        "    \"롬버드\": \"필립 롬버드\",\n",
        "    \"롬보드\": \"필립 롬버드\",\n",
        "    \"롬버드 대위\": \"필립 롬버드\",\n",
        "    \"필립\": \"필립 롬버드\",\n",
        "    \"필립 롬버드\": \"필립 롬버드\",\n",
        "\n",
        "    \"매커서\": \"존 고든 매커서\",\n",
        "    \"매커서 장군\": \"존 고든 매커서\",\n",
        "    \"매커스 장군\": \"존 고든 매커서\",\n",
        "    \"매커슨\": \"존 고든 매커서\",\n",
        "    \"매커센\": \"존 고든 매커서\",\n",
        "    \"장군\": \"존 고든 매커서\",\n",
        "\n",
        "    \"암스트롱\": \"에드워드 암스트롱\",\n",
        "    \"암스트롱 의사\": \"에드워드 암스트롱\",\n",
        "    \"의사\": \"에드워드 암스트롱\",\n",
        "\n",
        "    \"머스턴\": \"앤서니 머스턴\",\n",
        "    \"앤터니 머스턴\": \"앤서니 머스턴\",\n",
        "    \"앤터니\": \"앤서니 머스턴\",\n",
        "\n",
        "    \"블로어\": \"윌리엄 헨리 블로어\",\n",
        "\n",
        "    \"로저스\": \"토머스 로저스\",\n",
        "    \"로저스 부인\": \"에설 로저스\",\n",
        "    \"하인 로저스\": \"토머스 로저스\",\n",
        "    \"로저스 부부\": \"토머스 로저스\",\n",
        "    \"에설\": \"에설 로저스\",\n",
        "\n",
        "    # \"렉 경\": \"토머스 렉 경\",\n",
        "    # \"토머스 렉 경\": \"토머스 렉 경\",\n",
        "    # \"부경찰국장\": \"토머스 렉 경\",\n",
        "    # \"메인 경감\": \"메인 경감\",\n",
        "    \"전직 경감\": \"윌리엄 헨리 블로어\",\n",
        "    \"군인\": \"존 고든 매커서\",\n",
        "    # \"하녀\": \"비트리스 테일러\",\n",
        "\n",
        "    \"로버드 대위\": \"필립 롬버드\",\n",
        "    \"대위\": \"필립 롬버드\"\n",
        "}\n",
        "\n",
        "def normalize_name(name, alias_dict):\n",
        "    for alias, canonical in alias_dict.items():\n",
        "        if alias in name:\n",
        "            return canonical\n",
        "    return name\n",
        "\n",
        "def apply_alias_dict(rows, alias_dict):\n",
        "    for row in rows:\n",
        "        row[\"화자\"] = normalize_name(row[\"화자\"], alias_dict)\n",
        "        row[\"청자\"] = normalize_name(row[\"청자\"], alias_dict)\n",
        "    return rows\n",
        "\n",
        "\n",
        "file_list = [\n",
        "    \"대사_중복제거1.csv\",\n",
        "    \"대사_중복제거2.csv\",\n",
        "    \"대사_중복제거3.csv\",\n",
        "    \"대사_중복제거4.csv\"\n",
        "]\n",
        "\n",
        "# 각 파일 정규화 + 덮어쓰기\n",
        "for file in file_list:\n",
        "    df = pd.read_csv(file).fillna(\"불명\")\n",
        "    rows = df.to_dict(\"records\")\n",
        "    normalized_rows = apply_alias_dict(rows, alias_dict)\n",
        "    normalized_df = pd.DataFrame(normalized_rows)\n",
        "\n",
        "    # 덮어쓰기\n",
        "    normalized_df.to_csv(file, index=False)\n",
        "    print(f\"이름 정규화 완료 {file}\")"
      ],
      "metadata": {
        "id": "Fr3BCMGwyhrJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "ku8MfJzJkFsF"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}